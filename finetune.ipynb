{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d44IULegdgPF"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# This script finetunes the pretrained translation model on the binarized data using fairseq.\n",
        "\n",
        "%%shell\n",
        "echo `date`\n",
        "exp_dir=$1                              # path of the experiment directory\n",
        "model_arch=${2:-\"transformer_18_18\"}    # model architecture (defaults to `transformer_18_18`)\n",
        "pretrained_ckpt=$3                      # path to the pretrained checkpoint `.pt` file\n",
        "\n",
        "\n",
        "fairseq-train $exp_dir/final_bin \\\n",
        "--max-source-positions=256 \\\n",
        "--max-target-positions=256 \\\n",
        "--source-lang=SRC \\\n",
        "--target-lang=TGT \\\n",
        "--max-update=1000000 \\\n",
        "--save-interval-updates=1000 \\\n",
        "--arch=$model_arch \\\n",
        "--activation-fn gelu \\\n",
        "--criterion=label_smoothed_cross_entropy \\\n",
        "--label-smoothing=0.1 \\\n",
        "--optimizer adam \\\n",
        "--adam-betas \"(0.9, 0.98)\" \\\n",
        "--lr-scheduler=inverse_sqrt \\\n",
        "--clip-norm 1.0 \\\n",
        "--warmup-init-lr 1e-07 \\\n",
        "--lr 3e-5 \\\n",
        "--warmup-updates 2000 \\\n",
        "--dropout 0.2 \\\n",
        "--save-dir $exp_dir/model \\\n",
        "--keep-last-epochs 5 \\\n",
        "--keep-interval-updates 3 \\\n",
        "--patience 10 \\\n",
        "--skip-invalid-size-inputs-valid-test \\\n",
        "--fp16 \\\n",
        "--user-dir model_configs \\\n",
        "--update-freq=4 \\\n",
        "--distributed-world-size 8 \\\n",
        "--num-workers 24 \\\n",
        "--max-tokens 1024 \\\n",
        "--eval-bleu \\\n",
        "--eval-bleu-args \"{\\\"beam\\\": 1, \\\"lenpen\\\": 1.0, \\\"max_len_a\\\": 1.2, \\\"max_len_b\\\": 10}\" \\\n",
        "--eval-bleu-detok moses \\\n",
        "--eval-bleu-remove-bpe sentencepiece \\\n",
        "--eval-bleu-print-samples \\\n",
        "--best-checkpoint-metric bleu \\\n",
        "--maximize-best-checkpoint-metric \\\n",
        "--restore-file $pretrained_ckpt \\\n",
        "--reset-lr-scheduler \\\n",
        "--reset-meters \\\n",
        "--reset-dataloader \\\n",
        "--reset-optimizer \\\n",
        "--task translation\n"
      ]
    }
  ]
}